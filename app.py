import os
import warnings
import logging

# ============================================
# CONFIGURATION DES WARNINGS - DOIT √äTRE EN PREMIER
# ============================================
# Supprimer TOUS les warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Supprimer logs TensorFlow (0=all, 1=info, 2=warning, 3=error)
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
logging.getLogger('tensorflow').setLevel(logging.ERROR)

# Supprimer les warnings scikit-learn
import sklearn
sklearn.set_config(assume_finite=True)

# Maintenant importer le reste
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt

# Importer TensorFlow en mode silencieux
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
from tensorflow.keras.models import load_model

from sklearn.preprocessing import MinMaxScaler
import json

# Configuration de la page
st.set_page_config(
    page_title="Pr√©vision de Consommation √âlectrique",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

# Titre principal
st.markdown('<h1 class="main-header">‚ö° Pr√©vision de Consommation √âlectrique</h1>', unsafe_allow_html=True)

# Sidebar pour la navigation
st.sidebar.title("üìä Navigation")
page = st.sidebar.radio(
    "Choisir une page:",
    ["üè† Accueil", "üìà Pr√©dictions sur Fichier", "üéØ Pr√©diction Personnalis√©e", "üîç Exploration des Donn√©es", "üìä Comparaison des Mod√®les"]
)

# Fonction pour charger les mod√®les sans afficher warnings
@st.cache_resource(show_spinner=False)
def load_models():
    models = {}
    model_files = {
        "M√©diane": "median_model.pkl",
        "RNN": "rnn_model.h5",
        "LSTM Stacked": "lstm_stacked_model.h5",
        "BiLSTM": "bilstm_model.h5",
        "MLP": "mlp_model.h5",
        "CNN": "cnn_model.h5",
        "KMeans": "kmeans_model.pkl",
        "DBSCAN": "dbscan_model.pkl"
    }
    
    for name, file in model_files.items():
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                if file.endswith('.pkl'):
                    models[name] = joblib.load(file)
                elif file.endswith('.h5'):
                    models[name] = load_model(file, compile=False)
            st.sidebar.success(f"‚úì {name}")
        except FileNotFoundError:
            st.sidebar.warning(f"‚ö† {name} non trouv√©")
            models[name] = None
        except Exception as e:
            st.sidebar.error(f"‚úó {name} erreur")
            models[name] = None
    
    return models

# Fonction pour charger le scaler sans warnings
@st.cache_resource(show_spinner=False)
def load_scaler():
    try:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            return joblib.load("scaler.pkl")
    except:
        st.warning("‚ö† Scaler non trouv√©, cr√©ation d'un nouveau")
        return MinMaxScaler()

# Fonction pour cr√©er des s√©quences
def create_sequences(data, n_steps):
    X, y = [], []
    for i in range(len(data) - n_steps):
        X.append(data[i:i + n_steps])
        y.append(data[i + n_steps])
    return np.array(X), np.array(y)

# Fonction pour nettoyer les donn√©es
def clean_data(df):
    """
    Nettoie le DataFrame en rempla√ßant les valeurs invalides
    et en convertissant en num√©rique
    """
    # Remplacer les valeurs probl√©matiques
    df = df.replace('?', np.nan)
    df = df.replace('', np.nan)
    df = df.replace(' ', np.nan)
    
    # Convertir toutes les colonnes en num√©rique si possible
    for col in df.columns:
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        except:
            pass
    
    return df

# Fonction pour g√©rer les valeurs manquantes
def handle_missing_values(data, strategy='mean'):
    """
    G√®re les valeurs manquantes dans les donn√©es
    strategy: 'mean', 'median', 'forward', 'drop'
    """
    if isinstance(data, pd.DataFrame):
        missing_count = data.isnull().sum().sum()
    elif isinstance(data, pd.Series):
        missing_count = data.isnull().sum()
    else:
        return data
    
    if missing_count > 0:
        if strategy == 'mean':
            data = data.fillna(data.mean())
        elif strategy == 'median':
            data = data.fillna(data.median())
        elif strategy == 'forward':
            data = data.fillna(method='ffill').fillna(method='bfill')
        elif strategy == 'drop':
            data = data.dropna()
    
    return data

# ==================== PAGE ACCUEIL ====================
if page == "üè† Accueil":
    st.header("Bienvenue dans l'application de pr√©vision")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("### üìä Mod√®les Disponibles\n- M√©diane (Baseline)\n- RNN\n- LSTM Stacked\n- BiLSTM\n- MLP\n- CNN\n- KMeans & DBSCAN")
    
    with col2:
        st.success("### üéØ Objectif\nPr√©dire la consommation √©lectrique globale en utilisant diff√©rents algorithmes de ML et Deep Learning")
    
    with col3:
        st.warning("### üìÅ Donn√©es\nS√©rie temporelle de consommation √©lectrique avec plusieurs features")
    
    st.divider()
    
    # Charger les mod√®les
    models = load_models()
    
    st.subheader("üì¶ √âtat des Mod√®les")
    
    cols = st.columns(5)
    model_names = list(models.keys())
    
    for idx, name in enumerate(model_names):
        with cols[idx % 5]:
            if models[name] is not None:
                st.success(f"‚úÖ {name}")
            else:
                st.error(f"‚ùå {name}")

# ==================== PAGE PR√âDICTIONS SUR FICHIER ====================
elif page == "üìà Pr√©dictions sur Fichier":
    st.header("Pr√©dictions avec les Mod√®les")
    
    # Charger les mod√®les et scaler
    models = load_models()
    scaler = load_scaler()
    
    # Upload de fichier
    uploaded_file = st.file_uploader("üìÇ Charger un fichier CSV", type=['csv'])
    
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        
        # Nettoyer les donn√©es
        df = clean_data(df)
        
        # Afficher les infos sur les valeurs manquantes
        missing_before = df.isnull().sum().sum()
        
        st.success(f"‚úÖ Fichier charg√©: {df.shape[0]} lignes, {df.shape[1]} colonnes")
        
        if missing_before > 0:
            st.warning(f"‚ö†Ô∏è {missing_before} valeurs manquantes d√©tect√©es et nettoy√©es")
        
        # S√©lection de la colonne cible
        target_col = st.selectbox("S√©lectionner la colonne cible:", df.columns)
        
        # Option de gestion des valeurs manquantes
        missing_strategy = st.selectbox(
            "Strat√©gie pour les valeurs manquantes:",
            ["mean", "median", "forward", "drop"],
            help="mean: moyenne, median: m√©diane, forward: propagation, drop: suppression"
        )
        
        # Param√®tres
        col1, col2 = st.columns(2)
        
        with col1:
            n_steps = st.slider("Nombre de pas de temps (n_steps):", 5, 50, 10)
        
        with col2:
            test_size = st.slider("Taille du test (%):", 10, 40, 20)
        
        # S√©lection du mod√®le
        model_choice = st.selectbox(
            "Choisir un mod√®le:",
            ["M√©diane", "SARIMA", "RNN", "LSTM Stacked", "BiLSTM", "MLP", "CNN"]
        )
        
        if st.button("üöÄ Lancer la Pr√©diction"):
            with st.spinner(f"Pr√©diction en cours avec {model_choice}..."):
                
                # Pr√©paration des donn√©es avec nettoyage complet
                data_series = df[target_col].copy()
                
                # G√©rer les valeurs manquantes
                initial_missing = data_series.isnull().sum()
                if initial_missing > 0:
                    st.info(f"‚ÑπÔ∏è {initial_missing} valeurs manquantes trait√©es avec strat√©gie: {missing_strategy}")
                    data_series = handle_missing_values(data_series, strategy=missing_strategy)
                
                # V√©rifier qu'il reste des donn√©es
                if len(data_series) == 0:
                    st.error("‚ùå Pas assez de donn√©es apr√®s nettoyage")
                    st.stop()
                
                # Convertir en array numpy
                data = data_series.values.reshape(-1, 1)
                
                # V√©rifier les valeurs infinies
                if np.isinf(data).any():
                    st.warning("‚ö†Ô∏è Valeurs infinies d√©tect√©es et remplac√©es")
                    data = np.nan_to_num(data, nan=np.nanmean(data), posinf=np.nanmax(data[~np.isinf(data)]), neginf=np.nanmin(data[~np.isinf(data)]))
                
                # Normalisation
                try:
                    data_scaled = scaler.fit_transform(data)
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la normalisation: {str(e)}")
                    st.write("Aper√ßu des donn√©es:", data[:10])
                    st.stop()
                
                # Split train/test
                train_size = int(len(data_scaled) * (1 - test_size/100))
                train, test = data_scaled[:train_size], data_scaled[train_size:]
                
                model = models[model_choice]
                
                if model is not None:
                    try:
                        # Pr√©diction selon le type de mod√®le
                        if model_choice == "M√©diane":
                            y_pred = np.full(len(test), model)
                            y_test = test
                        
                        elif model_choice == "SARIMA":
                            forecast = model.forecast(len(test))
                            y_pred = forecast.values.reshape(-1, 1)
                            y_test = scaler.inverse_transform(test)
                            y_pred = y_pred
                        
                        elif model_choice in ["RNN", "LSTM Stacked", "BiLSTM", "CNN"]:
                            X_test, y_test = create_sequences(test, n_steps)
                            X_test_seq = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
                            with warnings.catch_warnings():
                                warnings.simplefilter("ignore")
                                y_pred = model.predict(X_test_seq, verbose=0)
                        
                        elif model_choice == "MLP":
                            X_test, y_test = create_sequences(test, n_steps)
                            with warnings.catch_warnings():
                                warnings.simplefilter("ignore")
                                y_pred = model.predict(X_test, verbose=0)
                        
                        # Inverse scaling
                        if model_choice != "SARIMA":
                            y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))
                            y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1))
                        else:
                            y_test_inv = y_test
                            y_pred_inv = y_pred
                        
                        # Calcul RMSE
                        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                        rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))
                        mae = mean_absolute_error(y_test_inv, y_pred_inv)
                        r2 = r2_score(y_test_inv, y_pred_inv)
                        
                        # Affichage des m√©triques
                        st.subheader("üìä M√©triques de Performance")
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("RMSE", f"{rmse:.4f}")
                        with col2:
                            st.metric("MAE", f"{mae:.4f}")
                        with col3:
                            st.metric("R¬≤ Score", f"{r2:.4f}")
                        
                        # Graphique
                        st.subheader("üìà Comparaison Valeurs R√©elles vs Pr√©dictions")
                        
                        fig, ax = plt.subplots(figsize=(12, 6))
                        
                        n_display = min(200, len(y_test_inv))
                        
                        ax.plot(y_test_inv[:n_display], label='Valeurs r√©elles', color='black', linewidth=2)
                        ax.plot(y_pred_inv[:n_display], label=f'Pr√©dictions {model_choice}', 
                               color='red', linestyle='--', linewidth=2)
                        
                        ax.set_title(f'Mod√®le {model_choice} - RMSE: {rmse:.4f}', fontsize=14, fontweight='bold')
                        ax.set_xlabel('Temps (√©chantillons)', fontsize=12)
                        ax.set_ylabel('Valeur', fontsize=12)
                        ax.legend(fontsize=11)
                        ax.grid(alpha=0.3)
                        
                        st.pyplot(fig)
                        
                        # Tableau des premi√®res pr√©dictions
                        st.subheader("üìã Premi√®res Pr√©dictions")
                        results_df = pd.DataFrame({
                            'Valeurs R√©elles': y_test_inv[:20].flatten(),
                            'Pr√©dictions': y_pred_inv[:20].flatten(),
                            'Erreur': np.abs(y_test_inv[:20].flatten() - y_pred_inv[:20].flatten())
                        })
                        st.dataframe(results_df, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la pr√©diction: {str(e)}")
                else:
                    st.error(f"Le mod√®le {model_choice} n'est pas disponible")

# ==================== PAGE PR√âDICTION PERSONNALIS√âE ====================
elif page == "üéØ Pr√©diction Personnalis√©e":
    st.header("üéØ Pr√©diction Personnalis√©e")
    st.info("üí° Entrez vos propres valeurs pour obtenir une pr√©diction")
    
    # Charger les mod√®les et scaler
    models = load_models()
    scaler = load_scaler()
    
    # Charger le fichier pour conna√Ætre les features disponibles
    uploaded_file = st.file_uploader("üìÇ Charger votre fichier CSV (pour r√©f√©rence des colonnes)", type=['csv'], key="custom_pred")
    
    if uploaded_file is not None:
        df_ref = pd.read_csv(uploaded_file)
        
        # Nettoyer les donn√©es avec la fonction
        df_ref = clean_data(df_ref)
        
        # G√©rer les valeurs manquantes
        df_ref = handle_missing_values(df_ref, strategy='mean')
        
        st.success(f"‚úÖ Fichier charg√©: {df_ref.shape[1]} colonnes disponibles")
        
        # Afficher les colonnes disponibles
        st.subheader("üìã Colonnes Disponibles")
        st.write(df_ref.columns.tolist())
        
        # S√©lection des features
        st.subheader("üîß Configuration de la Pr√©diction")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # S√©lection du mod√®le
            model_choice = st.selectbox(
                "Choisir un mod√®le:",
                ["M√©diane", "RNN", "LSTM Stacked", "BiLSTM", "MLP", "CNN"],
                key="model_custom"
            )
        
        with col2:
            n_steps = st.slider("Nombre de pas de temps:", 5, 50, 10, key="steps_custom")
        
        # S√©lection des features √† utiliser
        st.subheader("üìä S√©lection des Features")
        
        numeric_cols = df_ref.select_dtypes(include=['int64', 'float64']).columns.tolist()
        
        selected_features = st.multiselect(
            "Choisir les features pour la pr√©diction:",
            numeric_cols,
            default=numeric_cols[:min(3, len(numeric_cols))]
        )
        
        if selected_features:
            st.subheader("‚úèÔ∏è Entrez vos Valeurs")
            st.write(f"Vous devez entrer **{n_steps}** valeurs pour chaque feature s√©lectionn√©e")
            
            # Cr√©er des inputs pour chaque feature
            input_data = {}
            
            tabs = st.tabs(selected_features)
            
            for idx, feature in enumerate(selected_features):
                with tabs[idx]:
                    st.write(f"### {feature}")
                    
                    # Option: copier des valeurs du fichier
                    if st.checkbox(f"Utiliser des valeurs du fichier", key=f"use_file_{feature}"):
                        row_start = st.number_input(
                            f"Ligne de d√©part pour {feature}:", 
                            min_value=0, 
                            max_value=len(df_ref)-n_steps, 
                            value=0,
                            key=f"row_{feature}"
                        )
                        input_data[feature] = df_ref[feature].iloc[row_start:row_start+n_steps].values.tolist()
                        st.write(f"Valeurs s√©lectionn√©es: {input_data[feature]}")
                    else:
                        # Entr√©e manuelle
                        st.write("Entrez les valeurs (s√©par√©es par des virgules):")
                        values_str = st.text_input(
                            f"Valeurs pour {feature}:",
                            value=", ".join([str(round(df_ref[feature].mean(), 2))] * n_steps),
                            key=f"input_{feature}"
                        )
                        
                        try:
                            input_data[feature] = [float(x.strip()) for x in values_str.split(',')]
                            
                            if len(input_data[feature]) != n_steps:
                                st.error(f"‚ö†Ô∏è Vous devez entrer exactement {n_steps} valeurs!")
                        except:
                            st.error("‚ö†Ô∏è Format incorrect! Utilisez des nombres s√©par√©s par des virgules")
            
            # V√©rifier que toutes les features ont le bon nombre de valeurs
            all_valid = all(
                feature in input_data and len(input_data[feature]) == n_steps 
                for feature in selected_features
            )
            
            if all_valid:
                st.success(f"‚úÖ Toutes les valeurs sont correctes ({n_steps} valeurs par feature)")
                
                # Bouton de pr√©diction
                if st.button("üöÄ Faire la Pr√©diction", type="primary"):
                    with st.spinner("Pr√©diction en cours..."):
                        try:
                            model = models[model_choice]
                            
                            if model is not None:
                                # Pr√©parer les donn√©es
                                if len(selected_features) == 1:
                                    # Une seule feature
                                    input_array = np.array(input_data[selected_features[0]]).reshape(-1, 1)
                                else:
                                    # Plusieurs features
                                    input_array = np.array([input_data[f] for f in selected_features]).T
                                
                                # Normaliser
                                input_scaled = scaler.fit_transform(input_array)
                                
                                # Faire la pr√©diction selon le mod√®le
                                if model_choice == "M√©diane":
                                    prediction_scaled = model
                                
                                elif model_choice in ["RNN", "LSTM Stacked", "BiLSTM", "CNN"]:
                                    # Utiliser seulement la premi√®re colonne (target)
                                    input_seq = input_scaled[:, 0].reshape(1, n_steps, 1)
                                    with warnings.catch_warnings():
                                        warnings.simplefilter("ignore")
                                        prediction_scaled = model.predict(input_seq, verbose=0)[0][0]
                                
                                elif model_choice == "MLP":
                                    # Utiliser seulement la premi√®re colonne (target)
                                    input_flat = input_scaled[:, 0].reshape(1, -1)
                                    with warnings.catch_warnings():
                                        warnings.simplefilter("ignore")
                                        prediction_scaled = model.predict(input_flat, verbose=0)[0][0]
                                
                                # D√©normaliser
                                prediction = scaler.inverse_transform([[prediction_scaled]])[0][0]
                                
                                # Afficher le r√©sultat
                                st.subheader("üéâ R√©sultat de la Pr√©diction")
                                
                                col1, col2, col3 = st.columns([1, 2, 1])
                                
                                with col2:
                                    st.markdown(f"""
                                    <div style='text-align: center; padding: 2rem; background-color: #e3f2fd; border-radius: 1rem; border: 3px solid #1976d2;'>
                                        <h2 style='color: #1565c0; margin-bottom: 1rem;'>Pr√©diction</h2>
                                        <h1 style='color: #0d47a1; font-size: 3rem;'>{prediction:.4f}</h1>
                                        <p style='color: #424242; font-size: 1.2rem;'>Mod√®le: {model_choice}</p>
                                    </div>
                                    """, unsafe_allow_html=True)
                                
                                # Visualisation
                                st.subheader("üìä Visualisation")
                                
                                fig, ax = plt.subplots(figsize=(12, 6))
                                
                                # Tracer les valeurs d'entr√©e
                                x_input = list(range(n_steps))
                                y_input = input_data[selected_features[0]]
                                
                                ax.plot(x_input, y_input, 'o-', label='Valeurs d\'entr√©e', 
                                       color='blue', linewidth=2, markersize=8)
                                
                                # Tracer la pr√©diction
                                ax.plot([n_steps], [prediction], 'r*', 
                                       label='Pr√©diction', markersize=20)
                                
                                ax.axvline(x=n_steps-0.5, color='gray', linestyle='--', alpha=0.5)
                                
                                ax.set_xlabel('Pas de temps', fontsize=12)
                                ax.set_ylabel(selected_features[0], fontsize=12)
                                ax.set_title(f'Pr√©diction avec {model_choice}', fontsize=14, fontweight='bold')
                                ax.legend(fontsize=11)
                                ax.grid(alpha=0.3)
                                
                                st.pyplot(fig)
                                
                                # D√©tails
                                with st.expander("üìã D√©tails de la Pr√©diction"):
                                    st.write("**Valeurs d'entr√©e:**")
                                    for feature in selected_features:
                                        st.write(f"- {feature}: {input_data[feature]}")
                                    
                                    st.write(f"\n**Mod√®le utilis√©:** {model_choice}")
                                    st.write(f"**Nombre de pas de temps:** {n_steps}")
                                    st.write(f"**Valeur pr√©dite:** {prediction:.4f}")
                                
                            else:
                                st.error(f"Le mod√®le {model_choice} n'est pas disponible")
                        
                        except Exception as e:
                            st.error(f"Erreur lors de la pr√©diction: {str(e)}")
                            st.write("D√©tails de l'erreur:", e)
            else:
                st.warning("‚ö†Ô∏è Veuillez corriger les valeurs avant de continuer")

# ==================== PAGE EXPLORATION ====================
elif page == "üîç Exploration des Donn√©es":
    st.header("Exploration des Donn√©es")
    
    uploaded_file = st.file_uploader("üìÇ Charger un fichier CSV", type=['csv'], key="explore")
    
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        
        # Nettoyer les donn√©es
        df = clean_data(df)
        df = handle_missing_values(df, strategy='mean')
        
        st.subheader("üìä Aper√ßu des Donn√©es")
        st.dataframe(df.head(10), use_container_width=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Nombre de lignes", df.shape[0])
        with col2:
            st.metric("Nombre de colonnes", df.shape[1])
        with col3:
            st.metric("Valeurs manquantes", df.isnull().sum().sum())
        
        st.subheader("üìà Statistiques Descriptives")
        st.dataframe(df.describe(), use_container_width=True)
        
        # Histogrammes
        st.subheader("üìä Distribution des Variables Num√©riques")
        
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        selected_col = st.selectbox("S√©lectionner une colonne:", numeric_cols)
        
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.hist(df[selected_col].dropna(), bins=50, color='steelblue', edgecolor='black')
        ax.set_xlabel(selected_col, fontsize=12)
        ax.set_ylabel('Fr√©quence', fontsize=12)
        ax.set_title(f'Distribution de {selected_col}', fontsize=14, fontweight='bold')
        ax.grid(alpha=0.3)
        
        st.pyplot(fig)
        
        # S√©rie temporelle
        if st.checkbox("Afficher la s√©rie temporelle"):
            st.subheader("üìà Visualisation Temporelle")
            time_col = st.selectbox("Colonne temporelle:", df.columns)
            value_col = st.selectbox("Colonne de valeur:", numeric_cols)
            
            fig, ax = plt.subplots(figsize=(12, 5))
            ax.plot(df[time_col], df[value_col], color='darkblue', linewidth=1)
            ax.set_xlabel(time_col, fontsize=12)
            ax.set_ylabel(value_col, fontsize=12)
            ax.set_title(f'S√©rie Temporelle: {value_col}', fontsize=14, fontweight='bold')
            ax.grid(alpha=0.3)
            
            st.pyplot(fig)

# ==================== PAGE COMPARAISON ====================
elif page == "üìä Comparaison des Mod√®les":
    st.header("Comparaison des Performances des Mod√®les")
    
    # Donn√©es fictives pour la d√©monstration
    st.info("üí° Chargez vos r√©sultats ou lancez les pr√©dictions pour voir la comparaison")
    
    # Exemple de comparaison
    if st.checkbox("Afficher un exemple de comparaison"):
        models_rmse = {
            "M√©diane": 150.23,
            
            "RNN": 87.32,
            "LSTM Stacked": 78.90,
            "BiLSTM": 76.45,
            "MLP": 85.67,
            "CNN": 81.23
        }
        
        # Graphique en barres
        fig, ax = plt.subplots(figsize=(12, 6))
        
        models = list(models_rmse.keys())
        rmse_values = list(models_rmse.values())
        colors = plt.cm.viridis(np.linspace(0, 1, len(models)))
        
        bars = ax.bar(models, rmse_values, color=colors, edgecolor='black', linewidth=1.5)
        
        # Ajouter les valeurs sur les barres
        for bar, value in zip(bars, rmse_values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{value:.2f}',
                   ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        ax.set_xlabel('Mod√®les', fontsize=13, fontweight='bold')
        ax.set_ylabel('RMSE', fontsize=13, fontweight='bold')
        ax.set_title('Comparaison des RMSE par Mod√®le', fontsize=15, fontweight='bold')
        ax.grid(axis='y', alpha=0.3)
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        
        st.pyplot(fig)
        
        # Tableau de comparaison
        st.subheader("üìã Tableau R√©capitulatif")
        comparison_df = pd.DataFrame({
            'Mod√®le': models,
            'RMSE': rmse_values,
            'Rang': range(1, len(models) + 1)
        }).sort_values('RMSE')
        
        st.dataframe(comparison_df, use_container_width=True)
        
        # Meilleur mod√®le
        best_model = comparison_df.iloc[0]['Mod√®le']
        best_rmse = comparison_df.iloc[0]['RMSE']
        
        st.success(f"üèÜ Meilleur Mod√®le: **{best_model}** avec RMSE = **{best_rmse:.4f}**")

# Footer
st.divider()
st.markdown("""
    <div style='text-align: center; color: gray;'>
        <p>üìä Application de Pr√©vision de Consommation √âlectrique | D√©velopp√© avec Streamlit</p>
    </div>
""", unsafe_allow_html=True)